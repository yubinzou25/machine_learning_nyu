{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Video Game Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a whopping USD 138 billion per year, the video game industry has by now vastly outpaced the music and movie industry combined. For instance, one of the best generating box office opening (Avengers: Infinity Wars) generated about USD 259 million. In comparison, Grand Theft Auto V reached USD 818 million in sales in the first 24 hours.\n",
    "\n",
    "Even so, the gaming industry suffers from the same problems as the music and movie industries: it's a hit-driven business, meaning that the great majority of the video game industry's software releases have been commercial failures.\n",
    "\n",
    "In this scenario, we will investigate whether or not we can predict if a game will be a hit ... or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to submit on gradescope, you need to submit the following:\n",
    "- the homework jupyter notebook it self ```hw6.ipynb```\n",
    "- the pdf generated from the notebook, you can get the pdf from ```File->Print Preview```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/yx1215/Machine_Learning_Dataset/main/VideoGameSales.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the name column is just an index column, so we will remove it as we would not use it for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ...\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe contains 7 variables which we will use to predict the Global Sales (continuous). We are therefore dealing with a multi-variate regression problem. Before using ML to solve the problem, we want to have an overview of the data, so plotting is a good tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Sales each year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first would like to take a look at how global sales in general change every year, so we want to create a plot whose x-axis represents the year_of_release and y-axis represents the total_sale for each year.\n",
    "\n",
    "To create such plot, you might want to follow these steps:\n",
    "1. group the records by \"Year_of_Release\"\n",
    "2. extract the \"Global_Sales\" sum series\n",
    "3. apply plot() to the series\n",
    "\n",
    "You should be able to do this in one line of code using pandas.\n",
    "\n",
    "The following is how your plot should look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./pictures/year-vs-sales.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Sales each genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we want to look at sales for each genre. We want to create a bar chart whose x-axis represents the sales for each genrn while the y-axis represents different genre.\n",
    "\n",
    "To create such plot, you might want to follow these steps:\n",
    "1. group the dataframe by \"Genre\"\n",
    "2. extract the \"Global_Sales\" sum series\n",
    "3. to get barplots, use .plot.barh() on this series\n",
    "\n",
    "You should be able to do this in one line of code using pandas.\n",
    "\n",
    "The following is how your plot should look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./pictures/sales-per-genre.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train-Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, we would like to split the data set as the proper way of testing the validity of an algorithm is to have a test set and set it aside for future testing. We do not touch this test-set while training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[[\"Global_Sales\"]].values.ravel()\n",
    "\n",
    "# Generate dummies for all catagrical features\n",
    "X = pd.get_dummies(df.drop([\"Global_Sales\"], axis=1)).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0, shuffle=False)\n",
    "\n",
    "\n",
    "print(\"Original:\", X.shape)\n",
    "print(\"Train:   \", X_train.shape,y_train.shape)\n",
    "print(\"Test:    \", X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Note that we set the parameter shuffle=False when doing train-test split. Why is that?\n",
    "(Write your solutions here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train some models, we always want a target to beat. Normally, we will use the constant model whose prediction of any given data is the mean of the train data, because our model should at least be better than this naive prediction, otherwise the model would be meaningless.  \n",
    "\n",
    "So we would like to know the MSE for the simple constant model, write down the code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "constant_mse = ...\n",
    "print(\"Constant MSE: %.2f\" % constant_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we will look at is KNN Regression. sklearn has an implementation in ```sklearn.neighors```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train some knn models with different ks and see their performace on test set. Complete the following:\n",
    "- Train knn models for k from 2 to 50.\n",
    "- Draw a curve representing the relationship between k and test mse.\n",
    "- Draw the test mse for the constant model on the same graph(this should be a horizontal line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse_list = []\n",
    "k_range = range(2, 51)\n",
    "# train multiple knn models and record test mse\n",
    "for k in k_range:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plots\n",
    "plt.plot(..., label=\"test\")\n",
    "plt.plot(..., label=\"constant\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Compare the test mse for knn models with constant model, what do you find? How would you explain it?\n",
    "(Write your solutions here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Regularized Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will look at regularized model. We've seen L1/L2 regularized linear models in lecture. Sklearn has an efficient SGD(Stochastic Gradient Descent) implementation called SGDRegressor where allow us to solve regularized linear regression.  \n",
    "\n",
    "Compared to direct solver, SGDRegressor has the following advantages:\n",
    "- Efficiency\n",
    "- Ease of implementation (lots of opportunities for code tuning).  \n",
    "\n",
    "SGDRegressor has the following disadvantages:\n",
    "- SGD requires a number of hyperparameters such as the regularization parameter and the number of iterations.\n",
    "- SGD is sensitive to feature scaling.\n",
    "  \n",
    "  \n",
    "The following is an example of using it and it shows some parameters that you can tune with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "\n",
    "#limit the max_iter and set the random seed to fix the out put.\n",
    "sgd_model = SGDRegressor(\n",
    "    penalty=\"l1\",            # the type of regularization component to use, \n",
    "                             # l1 indicates Lasso and l2 indicats Ridge\n",
    "    max_iter=1000,           # maximal number of epochs\n",
    "    tol=1e-3,                # tolerance for the stopping condition (stops if it \n",
    "                             # can't improve the result more than tol), this speeds \n",
    "                             # up model building and is great for prototyping\n",
    "    alpha = 0.01,            # regularization strength, low = free model, high = controlled model\n",
    "    random_state=0           # random seed, fix the output, keep it 0 all the time in this hw\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting to a point where applying all the required steps for fitting a model is becoming cumbersome. Sklearn has a great feature called pipelines which allows you to apply all the necessary steps at once. For instance, consider a similar set-up to what we ended up with last time. We want to apply the following three steps:\n",
    "\n",
    "1. Scale the data using a StandardScaler\n",
    "2. Add polynomial features using PolynomialFeatures (in this section let's make degree=1)\n",
    "3. Train a linear model using SGDRegressor (in this section let's make penalty=l1 and alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./pictures/pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements this pipeline for our current dataset. Complete the pipeline and report the test mse.  \n",
    "\n",
    "Note: for all the sections below, whenever you train a SGDRegressor, please set the random seed to 0 to fix the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Design the pipeline as a sequence of steps each step\n",
    "# is specified as a tuple ('name',model). We will refer\n",
    "# to this name later.\n",
    "pipeline = ...\n",
    "\n",
    "# Train using the whole pipeline using just 1 call!\n",
    "...\n",
    "\n",
    "# Report the MSE on test data\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Customized Cross Vlidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we would like to train models and select the best parameters for them, we need to set-up a validation set. This validation set will be used for tuning parameters exclusively. This is a step that is often done wrong by novices in ML: you should never validate your parameters on the test-set. Doing so would cherry-pick the best solution and suffer from overfitting/variance problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./pictures/cross_validation.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we've seen it until now. In many cases, however, we will want to test it repeatedly on different parts of the data to get a more reliable out-of-sample estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./pictures/grid_search_cross_validation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final validation error is, therefore, a summary (mean) of 5 individual tests. In every test, we take a piece of the data out for the sake of validation (blue piece) and train on the remainder (green). This is how you should validate datasets without a time-component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, using this original way of kfold cv is also shuffling the data in some way and does not meet our requirement that we don't want to shuffle the data. In this case, we would want to split the data in the follwoing way instead:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./pictures/timeseriesval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default ```KFold()``` class in sklearn.model_selection does not handle this case, so we want to implement it ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that for k=5 we only do validation for 4(k-1) times\n",
    "# Input: data, an array inlucding all the train data you want to use for cv\n",
    "# Output: splits, a list of tuples in the form of (train_index, val_index), just as the kfold() in sklearn\n",
    "def customized_kfold(data, k):\n",
    "    n = data.shape[0] # we first get the number of data points we have for future sue\n",
    "    ...\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function for full cross validation\n",
    "# Input: X_train: full training X\n",
    "#        y_train: full training y\n",
    "#        k:       num of folds you want\n",
    "#        model:   the sklearn model that you would like to do cv on\n",
    "# Output: a tuple, (mean_train_mse, mean_val_mse)\n",
    "def kfold_cross_validation(X_train, y_train, k, model):\n",
    "    train_mse_list, val_mse_list = [], []\n",
    "    for train_index, val_index in customized_kfold(X_train, k):\n",
    "        ...\n",
    "    return (mean_train_mse, mean_val_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then do 10-fold cross validation with the functions you just write to find the best parameters for the following models and report the test mse for the best parameters you found for each model.\n",
    "- SGDRegressor with penalty=l1\n",
    "- SGDRegressor with penalty=l2\n",
    "- KNNRegressor  \n",
    "\n",
    "For SGDRegressor you only need to train alpha in ```[0, 0.001, 0.01, 0.1, 1, 5, 10]``` and degree in ```[1, 2]```, and for KNNRegressor you only need to train for k in ```range(10, 200, 10)```. Feel free to try larger search space but you might be careful with the run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 SGDRegressor with penalty=l1(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso = pipeline = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(...)),\n",
    "    ('sgd',  SGDRegressor(penalty=\"l1\",alpha=...,random_state=0)),\n",
    "])\n",
    "best_lasso.fit(X_train, y_train)\n",
    "mean_squared_error(best_lasso.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 SGDRegressor with penalty=l2(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge = pipeline = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(...)),\n",
    "    ('sgd',  SGDRegressor(penalty=\"l2\",alpha=...,random_state=0)),\n",
    "])\n",
    "best_ridge.fit(X_train, y_train)\n",
    "mean_squared_error(best_ridge.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = KNeighborsRegressor(...)\n",
    "best_knn.fit(X_train, y_train)\n",
    "mean_squared_error(best_knn.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. KNN Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have noticed that the performance for knn models are not that good. We would like to do something to improve its performance. We learned in class that l1 regularized regression can perform feature selection. Let's try it on our dataset.  \n",
    "\n",
    "Complete the following:\n",
    "- Run SGDRegressor again with l1 penalty and the best parameters you select from cv.\n",
    "- Find those features selected by the l1 regularized model and modify the dataset.\n",
    "- Run knn models for k in ```range(50, 2000, 100)```.\n",
    "- Make a plot of 1/k versus test mse.\n",
    "- Plot the test mse of the constant baseline model on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since numpy array does not have a count method, we might want to implement a \n",
    "# hepler function to find the index with zero and nonzero numbers.\n",
    "# Your implement does not need to take only one input, or you even don't need to implement \n",
    "# this to finish the hw, this function is only used to make it easier for you to solve the\n",
    "# remaining problems.\n",
    "def find_zero_and_nonezero_index(lst, ...):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug in the best params you just find.\n",
    "pipeline = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(...)),\n",
    "    ('sgd',  SGDRegressor(penalty=\"l1\", alpha=...,random_state=0)),\n",
    "])\n",
    "\n",
    "# Train using the whole pipeline using just 1 call!\n",
    "pipeline.fit(X_train,y_train)\n",
    "\n",
    "# Find the coeficients for the SGDRegressor\n",
    "# Hint: You can retreive the model for each step in the pipeline use pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the zero and nonzero index.\n",
    "# This step is optional, if you think you don't need it, you can skip it.\n",
    "# Hint: Does the number of features you retrieve from the pipeline matches the number of \n",
    "#       features in the original dataframe?\n",
    "nonzero_index, zero_index = find_zero_and_nonezero_index(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse_list = []\n",
    "train_mse_list = []\n",
    "k_range = range(50, 2000, 100)\n",
    "for k in k_range:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [1/k for k in k_range]\n",
    "plt.plot(..., label=\"test\")\n",
    "plt.plot(..., label=\"constant\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Compare this plot with what you have in section5, is there any difference between them? If so what caused such differences?\n",
    "(Write your solutions here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to compare how train and test mse changes. Complete the following:\n",
    "- Make two subplots in the same row, the left one should be 1/k versus train mse, and the right one should be 1/k versus test mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=[6, 3], dpi=200)\n",
    "k_list = [1/k for k in k_range]\n",
    "subplot = plt.subplot(...)\n",
    "subplot.plot(..., label=\"train\")\n",
    "plt.legend()\n",
    "subplot = plt.subplot(...)\n",
    "subplot.plot(..., label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: How do the trends differ for train mse from test mse? Explain the reason.\n",
    "(Write your solutions here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 More on features deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In last section we train knn models on those features selected by Lasso, now we will take a look at what will happen if we train on those features that are deleted. Complete the following:  \n",
    "- Find the features deleted by lasso\n",
    "- Run knn models for k in ```range(50, 2000, 100)```\n",
    "- Make two subplots in the same row, the left one should be 1/k versus train mse, and the right one should be 1/k versus test mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mse_list = []\n",
    "train_mse_list = []\n",
    "k_range = range(50, 2000, 100)\n",
    "\n",
    "for k in k_range:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=[6, 3], dpi=200)\n",
    "k_list = [1/k for k in k_range]\n",
    "subplot = plt.subplot(...)\n",
    "subplot.plot(..., label=\"train\")\n",
    "plt.legend()\n",
    "subplot = plt.subplot(...)\n",
    "subplot.plot(..., label=\"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Are the trends for train mse and test mse the same with what you have in section 8.1? If not what are the differences? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Cross Validation with Modified Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have modified the dataset according to lasso. Please retrain the following model on the modified dataset you have and find the best parameters for them.\n",
    "- SGDRegressor with penalty=l1\n",
    "- SGDRegressor with penalty=l2\n",
    "- KNNRegressor  \n",
    "\n",
    "For SGDRegressor you only need to train alpha in ```[0, 0.001, 0.01, 0.1, 1, 5, 10]``` and degree in ```[1, 2]```, and for KNNRegressor you only need to train for k in ```range(10, 200, 10)```. Feel free to try larger search space but you might be careful with the run time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 SGDRegressor with penalty=l1(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso = pipeline = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(...)),\n",
    "    ('sgd',  SGDRegressor(penalty=\"l1\",alpha=...,random_state=0)),\n",
    "])\n",
    "best_lasso.fit(...)\n",
    "mean_squared_error(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 SGDRegressor with penalty=l2(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge = pipeline = Pipeline([\n",
    "    ('ss', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(...)),\n",
    "    ('sgd',  SGDRegressor(penalty=\"l2\",alpha=...,random_state=0)),\n",
    "])\n",
    "best_ridge.fit(...)\n",
    "mean_squared_error(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = KNeighborsRegressor(...)\n",
    "best_knn.fit(...)\n",
    "mean_squared_error(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Compare the test mse with what you have in section 7, is there any improvements? How much does each model improve? How would you explain the difference in the improvements?\n",
    "(Write your solutions here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What is your final choice for the model type and its parameter(s)? Explain your reason.\n",
    "(Write your solutions here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
