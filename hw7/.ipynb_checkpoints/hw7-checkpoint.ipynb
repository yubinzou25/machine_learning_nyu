{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we are going through the application of different classification methods and related concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to submit on gradescope, you need to submit the following:\n",
    "- the homework jupyter notebook it self ```hw7.ipynb```\n",
    "- the pdf generated from the notebook, you can get the pdf from ```File->Print Preview```\n",
    "- the .py file generated from the notebook, you can get the .py file from ```File->Download as->Python(.py)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. QMNIST Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import pickle\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "train_data = ...\n",
    "train_labels = ...\n",
    "\n",
    "test_data = ...\n",
    "test_labels = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Plot your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each QMNIST data point represents a 28 * 28 pixel hand written digit. Complete the following code to plot the first five data point from the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array.reshape might be useful.\n",
    "fig, axes = plt.subplots(1, 5, figsize=(6, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(5):\n",
    "    ...\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn has two different implementions of naive bayes that we can use for this problem: \n",
    "- ```CategoricalNB()```\n",
    "- ```GaussianNB()```  \n",
    "\n",
    "Let's take a loot at both of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 CategoricalNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CategoricalNB, we assume that each feature in the dataset is categorical. Therefore, the The probability of category $t$ in feature $i$ given class $c$ is estimated as:  \n",
    "<div align='center'>\n",
    "    <span style=\"font-size:1.5em;\">$P(x_i=t|y=c; \\alpha)=\\frac{N_tic+\\alpha}{N_c+\\alpha n_i}$</span>\n",
    "</div>\n",
    "This is just what we see in class, with $\\alpha$ being the smoothing variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task here is to draw out the test accuracy score for $\\alpha$ between 0 and 2 with step to be 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Describe how test accuracy changes and explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In GaussainNB, we no longer assume each feature is categorical. Instead, we assume the likelyhood of each feature follows a Gaussain Distribution:\n",
    "\n",
    "<div align='center'>\n",
    "    <span style=\"font-size:1.5em;\">$P(x_i|y)=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}_{y}}}\\exp{(-\\frac{(x_i-\\mu_y)^2}{2\\sigma_y^2})}$</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again draw out the test accuracy score for $var\\_smoothing$ between 0 and 2 with step to be 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the plot\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Compare the performance of the model with $var\\_smoothing=0$ and the model with $var\\_smoothing$ being other values. What do you find? How would you explain this senario? \n",
    "Hint: Take a look at the warning messages generated when you run the models. sklearn documentation might also be useful. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Comparing the test accuracy between the above two different Naive Bayes models. Which one has a relatively low score? What might be the cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we would like to analyze the confusion matrix of a given model.\n",
    "\n",
    "The following is the definition of a confusion matrix:  \n",
    "\n",
    "By definition a confusion matrix $C$ is such that $C_{i, j}$\n",
    "is equal to the number of observations known to be in group $i$ and\n",
    "predicted to be in group $j$.\n",
    "\n",
    "For confusion matrix, use `sklearn.metrics.confusion_matrix`\n",
    "\n",
    "Firstly, compute confusion matrix using ```CategoricalNB``` with $\\alpha=0.5$ and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "...\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in labels],\n",
    "                  columns = [i for i in labels])\n",
    "# print(df_cm)\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What are the top five confusing pairs (i -> j) of classes for you model? What might be the cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have gone over a problem with 10 classes. Let's take a deeper look at the classification on a relatively simple dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Binary Dateset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have two binary datasets in the fold you downloaded. Let's first take a look at the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('binary_dataset1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the class distribution. Your task here is to draw a bar chart with each bar representing a simple class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the bar chart\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training any model, you need to get the X and y out of the dataframe and do train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y from the dataset\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train test split with random_state=0 and test_size=0.5\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Naive Bayes in Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to solve this problem using Naive Bayes model with proper parameter. Choose a proper Naive Bayes class to solve this priblem. Report your test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Using Regression for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a binary classification problem, we can solve it in the following steps:\n",
    "1. Fit a linear regression model\n",
    "2. Get your raw predicted values $x_r$ from the model\n",
    "3. Find a threshold $\\epsilon$ in a way such that \n",
    "4. Get your final predicted class $x_c$ in a way that $x_c=0$ if $x_r<\\epsilon$, otherwsie $x_c=1$  \n",
    "\n",
    "One way to choose the $\\epsilon$ here is to find the one that maximize the train accuracy, and then apply to test data.  \n",
    "\n",
    "So your task here is to create such a model, find $\\epsilon$, and report test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down what you find here:\n",
    "- $\\epsilon$ =\n",
    "- train_accuracy = \n",
    "- test_accuracy = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Can you think of any model you learnt from class that is similar to this way of doing classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Binary dataset 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's take a look at the second binary dataset.  \n",
    "\n",
    "As usual, we take a look at the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('binary_dataset2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Compare the distribution with the first dataset. What do you find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again you need to get the X and y out the dataframe and do train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X and y from dataset\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do train test split with random_state=0 and test_size=0.5\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Accuracy for Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a Naive Bayes model again. Similar with 2.1.1, choose a proper Naive Bayes class with a proper smoothing variable to solve this priblem. Report your test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: According to your accuracy score, how would you evaluate your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Confusion Matrix and Different Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./pictures/confusionmatrix.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important tool to debug classifiers is the confusion matrix. For binary classification, it contains four different cells:\n",
    "\n",
    "- **True positives (TP)**: observations that were predicted as belonging to the positive class correctly.\n",
    "\n",
    "- **False positives (FP)**: observations that were predicted as belonging to the positive class incorrectly.\n",
    "\n",
    "- **True negatives (TN)**: observations that were predicted as belonging to the negative class correctly.\n",
    "\n",
    "- **False negatives (FN)**: observations that were predicted as belonging to the negative class incorrectly.\n",
    "\n",
    "These are all interesting in and of themselves, but they can also be combined in aggregate metrics such as:\n",
    "\n",
    "- **Accuracy**: how often are we predicting the class label?\n",
    "- **Precision**: how many of our positive outcomes are actually positive?\n",
    "- **Recall/Sensitivity**: how many of the positive outcomes are we able to recall?\n",
    "- **Fall-Out**: how many of our negative outcomes are actually positive?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose each data point in the data set represents a patient, and the class 1 represensts a patient is tested positive for a desease while 0 means tested negative. Choose a metric and report the metric score you choose for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw your confusion matrix here\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the metric you chose here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: Is the metric you chose higher is better or lower is better in this situation? What would you say about your model using the metric you chose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
